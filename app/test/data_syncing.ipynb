{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50f343a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2860c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_pass = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "            host=db_host,\n",
    "            database=db_name,\n",
    "            user=db_user,\n",
    "            password=db_pass\n",
    ")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c890c1",
   "metadata": {},
   "source": [
    "## Voluum Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7790dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customVariable1</th>\n",
       "      <th>reason</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.480000e+11</td>\n",
       "      <td>INVALID_PHONE</td>\n",
       "      <td>AI_AGENT_OSversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.480000e+11</td>\n",
       "      <td>INVALID_PHONE</td>\n",
       "      <td>AI_AGENT_OSversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.480000e+11</td>\n",
       "      <td>INVALID_PHONE</td>\n",
       "      <td>AI_AGENT_OSversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.480000e+11</td>\n",
       "      <td>INVALID_PHONE</td>\n",
       "      <td>AI_AGENT_OSversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.480000e+11</td>\n",
       "      <td>INVALID_PHONE</td>\n",
       "      <td>AI_AGENT_OSversion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customVariable1         reason              source\n",
       "0     4.480000e+11  INVALID_PHONE  AI_AGENT_OSversion\n",
       "1     4.480000e+11  INVALID_PHONE  AI_AGENT_OSversion\n",
       "2     4.480000e+11  INVALID_PHONE  AI_AGENT_OSversion\n",
       "3     4.480000e+11  INVALID_PHONE  AI_AGENT_OSversion\n",
       "4     4.480000e+11  INVALID_PHONE  AI_AGENT_OSversion"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"../data/COMPL_GLOBAL_BL_CLK36M_TSLOG_MMD_04122025-V2_bot_HLRAJ_v3.4.csv\")\n",
    "data_df = data_df[['customVariable1', 'reason', 'source']]\n",
    "data_df.loc[data_df['reason']=='Invalid_phone', 'reason'] = 'INVALID_PHONE'\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60582eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['customVariable1'] = pd.to_numeric(data_df['customVariable1'], errors='coerce')\n",
    "data_df = data_df.dropna(subset=['customVariable1'])\n",
    "data_df = data_df[\n",
    "    (data_df['customVariable1'] != '') & \n",
    "    (data_df['customVariable1'].notnull())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7373d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[['customVariable1']].astype(int).to_csv('../data/cleaned_blacklist_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64069d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         447999998980\n",
       "1         447999998262\n",
       "2         447999998172\n",
       "3         447999997175\n",
       "4         447999996691\n",
       "              ...     \n",
       "349458      4530414419\n",
       "349459      4524910837\n",
       "349460      4523429009\n",
       "349461      4524476611\n",
       "349462      4521324046\n",
       "Name: customVariable1, Length: 349463, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['customVariable1'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a52981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[447999998980.0, 'INVALID_PHONE', 'AI_AGENT_OSversion'],\n",
       "       [447999998262.0, 'INVALID_PHONE', 'AI_AGENT_OSversion'],\n",
       "       [447999998172.0, 'INVALID_PHONE', 'AI_AGENT_OSversion'],\n",
       "       [447999997175.0, 'INVALID_PHONE', 'AI_AGENT_OSversion'],\n",
       "       [447999996691.0, 'INVALID_PHONE', 'AI_AGENT_OSversion']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_df.to_numpy()\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2bd59",
   "metadata": {},
   "source": [
    "## Insert into ts source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cfd20b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted final batch of 349463 records into api_voluum_ts_sources.\n"
     ]
    }
   ],
   "source": [
    "insert_query = f\"\"\"\n",
    "INSERT INTO public.\"api_voluum_ts_sources\" ( custom_variable_1, timestamp_created, category, data_source\n",
    ") VALUES %s\n",
    "\"\"\"\n",
    "rows = []\n",
    "now = datetime.now()\n",
    "for record in data:\n",
    "    rows.append((\n",
    "        int(record[0]), now, 'BLACKLIST', record[2]\n",
    "    ))\n",
    "if rows:\n",
    "    execute_values(cursor, insert_query, rows, page_size=50000)\n",
    "    connection.commit()\n",
    "    print(f\"Inserted final batch of {len(rows)} records into api_voluum_ts_sources.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfae7b0",
   "metadata": {},
   "source": [
    "## Insert into Blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea65e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted/Updated final batch of 349463 records into Blacklist.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "INSERT INTO public.\"blacklist\" ( custom_variable_1, timestamp_created, source, reason)\n",
    "VALUES %s\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "now = datetime.now()\n",
    "rows = []\n",
    "\n",
    "for record in data:\n",
    "    rows.append((\n",
    "        int(record[0]), now, record[2], record[1]\n",
    "    ))\n",
    "\n",
    "# Flush remaining\n",
    "if rows:\n",
    "    execute_values(cursor, query, rows, page_size=50000)\n",
    "    connection.commit()\n",
    "    print(f\"Inserted/Updated final batch of {len(rows)} records into Blacklist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a522573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def export_table_to_csv_fast(table_name, output_dir=\"exports\"):\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_path = Path(output_dir) / f\"{table_name}_{timestamp}.csv\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "        COPY \"{table_name}\"\n",
    "        TO STDOUT WITH CSV HEADER\n",
    "    \"\"\"\n",
    "\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        cursor.copy_expert(query, f)\n",
    "\n",
    "    print(f\"✅ Exported table using COPY to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b3f7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35900/4122231224.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported table using COPY to exports/whitelist_20260115_124341.csv\n"
     ]
    }
   ],
   "source": [
    "export_table_to_csv_fast(\"whitelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af971efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM api_voluum_conversions avc \n",
    "WHERE avc.processed_at   >= NOW() - INTERVAL '24 hours';\n",
    "\"\"\"\n",
    "cursor = connection.cursor()\n",
    "response = cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c40f445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7526aaf",
   "metadata": {},
   "source": [
    "## Conversions Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97c7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import json\n",
    "from uuid import uuid4\n",
    "\n",
    "country_codes = json.load(open('../utils/country_codes.json', 'r'))\n",
    "\n",
    "def insert_conversions(data):\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO public.\"api_voluum_conversions\" (uuid, click_id, postback_timestamp, processed, processed_at, error_message, retry_count, last_retry_at, generated_email, custom_variable_1, affiliate_network_id, affiliate_network_name, browser, browser_version,campaign_id, campaign_name, city, connection_type, conversion_type, conversion_type_id, cost, country_code, country_name,custom_variable_10, custom_variable_2, custom_variable_3,custom_variable_4, custom_variable_5, custom_variable_6,custom_variable_7, custom_variable_8, custom_variable_9,device, device_name, external_id, external_id_type, flow_id,ip, isp, lander_id, lander_name, language, offer_id, offer_name,os, os_version, path_id, profit, referrer, region, revenue, traffic_source_id, traffic_source_name, transaction_id, user_agent, visit_timestamp, source)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (click_id, transaction_id, conversion_type)\n",
    "    DO NOTHING\n",
    "    \"\"\"\n",
    "    # 7, 39, false, now, null, 0, null, generated_email, 14, 0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48\n",
    "    rows = []\n",
    "    now = datetime.now()\n",
    "    start_time = time()\n",
    "    for record in data:\n",
    "        uuid_new = str(uuid4())\n",
    "        country_code = country_codes.get(record[5].split(' - ')[1], \"DEF\")\n",
    "        conversion_type = \"REG\" if record[9] != \"FTD\" else \"FTD\"\n",
    "        generated_email = '+' + record[14] + '@yourmobile.com' if record[14] and record[14].strip() and record[14].strip().lower() != '<na>' else None\n",
    "        rows.append((\n",
    "            uuid_new, record[7], record[39], False, now, None, 0, None, generated_email,\n",
    "            record[14], record[0], record[1], record[2], record[3], record[4], \n",
    "            record[5], record[6], record[8], conversion_type, record[10], record[11], country_code,\n",
    "            record[13], record[15], record[16], record[17], record[18], record[19],\n",
    "            record[20], record[21], record[22], record[23], record[24], record[25],\n",
    "            record[26], record[27], record[28], record[29], record[30], record[31],\n",
    "            record[32], record[33], record[34], record[35], record[36], record[37],\n",
    "            record[38], record[40], record[41], record[42], record[43], record[44],\n",
    "            record[45], record[46], record[47], record[48], country_code + \"_\" + conversion_type\n",
    "        ))\n",
    "\n",
    "    print(f\"Data prepared for insertion in {time() - start_time} seconds.\")\n",
    "    if rows:\n",
    "        execute_values(cursor, insert_query, rows, page_size=10000)\n",
    "        connection.commit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd87f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def create_session_token():\n",
    "    url = \"https://api.voluum.com/auth/access/session\"\n",
    "\n",
    "    payload = {\n",
    "        \"accessId\": os.getenv(\"VOLUUM_ACCESS_ID\"),\n",
    "        \"accessKey\": os.getenv(\"VOLUUM_ACCESS_KEY\")\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    return response.json()[\"token\"]\n",
    "\n",
    "def get_conversions_data(limit=\"500\", from_date=\"2025-12-06T00:00:00.000Z\", to_date=\"2025-12-13T00:00:00.000Z\"):\n",
    "    url = f\"https://api.voluum.com/report/conversions?column=clickId&column=transactionId&column=visitTimestamp&column=postbackTimestamp&column=revenue&column=cost&column=profit&column=campaignId&column=campaignName&column=offerId&column=offerName&column=landerId&column=landerName&column=flowId&column=pathId&column=trafficSourceId&column=trafficSourceName&column=conversionType&column=conversionTypeId&column=referrer&column=affiliateNetworkId&column=affiliateNetworkName&column=countryCode&column=countryName&column=region&column=city&column=ip&column=isp&column=connectionType&column=deviceName&column=os&column=osVersion&column=browser&column=browserVersion&column=userAgent&column=language&column=status&column=customVariable1&column=customVariable2&column=customVariable3&column=customVariable4&column=customVariable5&column=customVariable6&column=customVariable7&column=customVariable8&column=customVariable9&column=customVariable10&column=externalId&column=externalIdType&from={from_date}&to={to_date}&limit={limit}&offset=OFFSET_VALUE&currency=EUR\"\n",
    "    access_token = create_session_token()\n",
    "\n",
    "    headers = {\n",
    "        \"cwauth-token\": access_token\n",
    "    }\n",
    "    total_data = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        paginated_url = url.replace(\"OFFSET_VALUE\", str(offset))\n",
    "        response = requests.get(paginated_url, headers=headers)\n",
    "        data = response.json()\n",
    "        total_data.extend(data['rows'])\n",
    "        print(f\"Fetched {len(data['rows'])} rows at offset {offset} out of {data['totalRows']} total rows. Current total: {len(total_data)}\")\n",
    "        if len(total_data) == int(data[\"totalRows\"]):\n",
    "            break\n",
    "        offset += int(limit)\n",
    "    return total_data\n",
    "\n",
    "def get_conversions_data_as_dataframe(limit=\"500\", from_date=\"2025-12-06T00:00:00.000Z\", to_date=\"2025-12-13T00:00:00.000Z\"):\n",
    "        data = get_conversions_data(limit, from_date, to_date)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d078b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 500 rows at offset 0 out of 1484 total rows. Current total: 500\n",
      "Fetched 500 rows at offset 500 out of 1484 total rows. Current total: 1000\n",
      "Fetched 484 rows at offset 1000 out of 1484 total rows. Current total: 1484\n"
     ]
    }
   ],
   "source": [
    "# data = get_conversions_data_as_dataframe(from_date=\"2025-10-01T00:00:00.000Z\", to_date=\"2025-10-02T00:00:00.000Z\")\n",
    "data_big = get_conversions_data_as_dataframe(from_date=\"2025-10-31T00:00:00.000Z\", to_date=\"2025-11-01T00:00:00.000Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad5d2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1484"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(data)\n",
    "# df = df.sort_values(by='postbackTimestamp')\n",
    "df_big = pd.DataFrame(data_big)\n",
    "df_big = df_big.sort_values(by='postbackTimestamp')\n",
    "len(df_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45a26f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postbackTimestamp</th>\n",
       "      <th>revenue</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2025-10-01 04:17:21 AM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2025-10-01 04:20:43 AM</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          postbackTimestamp  revenue     region\n",
       "458  2025-10-01 04:17:21 AM      0.0  Liverpool\n",
       "459  2025-10-01 04:20:43 AM    300.0  Liverpool"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[[\"postbackTimestamp\", \"revenue\", \"region\"]][df.postbackTimestamp >= '2025-10-01 04:20:11 AM'][:10].sort_values(by='postbackTimestamp')\n",
    "# df[[\"postbackTimestamp\", \"revenue\", \"region\"]][df.revenue.round(2) == 300][15:25].sort_values(by='postbackTimestamp')\n",
    "df[[\"postbackTimestamp\", \"revenue\", \"region\"]][df.clickId == \"wepghap9uhm2r44djmt0lv2q\"].sort_values(by='postbackTimestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7994769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postbackTimestamp</th>\n",
       "      <th>revenue</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>2025-10-01 04:17:21 AM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16598</th>\n",
       "      <td>2025-10-01 04:17:21 AM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>2025-10-01 04:20:43 AM</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16599</th>\n",
       "      <td>2025-10-01 04:20:43 AM</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            postbackTimestamp  revenue     region\n",
       "4680   2025-10-01 04:17:21 AM      0.0  Liverpool\n",
       "16598  2025-10-01 04:17:21 AM      0.0  Liverpool\n",
       "4681   2025-10-01 04:20:43 AM    300.0  Liverpool\n",
       "16599  2025-10-01 04:20:43 AM    300.0  Liverpool"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_big[[\"postbackTimestamp\", \"revenue\", \"region\"]][df_big.postbackTimestamp >= '2025-10-01 04:20:11 AM'][:10].sort_values(by='postbackTimestamp')\n",
    "df_big[[\"postbackTimestamp\", \"revenue\", \"region\"]][(df_big.clickId == \"wepghap9uhm2r44djmt0lv2q\")].sort_values(by='postbackTimestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed428892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(390070.57364147005)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d4443cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows with 2 or more duplicates for columns 'postbackTimestamp' and 'clickId'\n",
    "df_duplicates = df[df.groupby(['postbackTimestamp', 'clickId'])['clickId'].transform('size') >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a07830da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postbackTimestamp</th>\n",
       "      <th>clickId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>2025-10-02 12:34:08 PM</td>\n",
       "      <td>wkblrq2fqf5i045d3q2hk7ci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>2025-10-02 12:34:08 PM</td>\n",
       "      <td>wkblrq2fqf5i045d3q2hk7ci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>2025-10-04 01:40:19 PM</td>\n",
       "      <td>w7hopr2o68lctl6d3v12ta9c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>2025-10-04 01:40:19 PM</td>\n",
       "      <td>w7hopr2o68lctl6d3v12ta9c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>2025-10-01 11:07:49 PM</td>\n",
       "      <td>wgqkrpd8nkvuvn4d3n7crduq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>2025-10-01 11:07:49 PM</td>\n",
       "      <td>wgqkrpd8nkvuvn4d3n7crduq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2025-10-04 04:14:14 PM</td>\n",
       "      <td>wc8irum83n4mun6djsl1nu6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2025-10-04 04:14:14 PM</td>\n",
       "      <td>wc8irum83n4mun6djsl1nu6f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           postbackTimestamp                   clickId\n",
       "897   2025-10-02 12:34:08 PM  wkblrq2fqf5i045d3q2hk7ci\n",
       "898   2025-10-02 12:34:08 PM  wkblrq2fqf5i045d3q2hk7ci\n",
       "1224  2025-10-04 01:40:19 PM  w7hopr2o68lctl6d3v12ta9c\n",
       "1225  2025-10-04 01:40:19 PM  w7hopr2o68lctl6d3v12ta9c\n",
       "1516  2025-10-01 11:07:49 PM  wgqkrpd8nkvuvn4d3n7crduq\n",
       "1517  2025-10-01 11:07:49 PM  wgqkrpd8nkvuvn4d3n7crduq\n",
       "1822  2025-10-04 04:14:14 PM  wc8irum83n4mun6djsl1nu6f\n",
       "1823  2025-10-04 04:14:14 PM  wc8irum83n4mun6djsl1nu6f"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicates[['postbackTimestamp', 'clickId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebdccd8",
   "metadata": {},
   "source": [
    "## Day by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a263b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_conversions_data_day_by_day(\n",
    "    start_date=\"2025-12-06\",\n",
    "    end_date=\"2025-12-13\",\n",
    "    limit=5000\n",
    "):\n",
    "    access_token = create_session_token()\n",
    "\n",
    "    headers = {\n",
    "        \"cwauth-token\": access_token\n",
    "    }\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    start_dt = datetime.fromisoformat(start_date)\n",
    "    end_dt = datetime.fromisoformat(end_date)\n",
    "\n",
    "    current_day = start_dt\n",
    "    calculations = {}\n",
    "    while current_day <= end_dt:\n",
    "        day_start = current_day.strftime(\"%Y-%m-%dT00:00:00.000Z\")\n",
    "        day_end = (current_day + timedelta(days=1)).strftime(\"%Y-%m-%dT00:00:00.000Z\")\n",
    "\n",
    "        print(f\"\\nFetching data for {current_day.date()}\")\n",
    "\n",
    "        base_url = (\n",
    "            \"https://api.voluum.com/report/conversions?\"\n",
    "            \"column=clickId&column=transactionId&column=visitTimestamp&column=postbackTimestamp\"\n",
    "            \"&column=revenue&column=cost&column=profit\"\n",
    "            \"&column=campaignId&column=campaignName\"\n",
    "            \"&column=offerId&column=offerName\"\n",
    "            \"&column=landerId&column=landerName\"\n",
    "            \"&column=flowId&column=pathId\"\n",
    "            \"&column=trafficSourceId&column=trafficSourceName\"\n",
    "            \"&column=conversionType&column=conversionTypeId\"\n",
    "            \"&column=referrer\"\n",
    "            \"&column=affiliateNetworkId&column=affiliateNetworkName\"\n",
    "            \"&column=countryCode&column=countryName\"\n",
    "            \"&column=region&column=city&column=ip\"\n",
    "            \"&column=isp&column=connectionType\"\n",
    "            \"&column=deviceName&column=os&column=osVersion\"\n",
    "            \"&column=browser&column=browserVersion\"\n",
    "            \"&column=userAgent&column=language\"\n",
    "            \"&column=status\"\n",
    "            \"&column=customVariable1&column=customVariable2&column=customVariable3\"\n",
    "            \"&column=customVariable4&column=customVariable5\"\n",
    "            \"&column=customVariable6&column=customVariable7\"\n",
    "            \"&column=customVariable8&column=customVariable9&column=customVariable10\"\n",
    "            \"&column=externalId&column=externalIdType\"\n",
    "            f\"&from={day_start}&to={day_end}\"\n",
    "            f\"&limit={limit}&offset={{offset}}&currency=EUR\"\n",
    "        )\n",
    "\n",
    "        offset = 0\n",
    "        day_rows = []\n",
    "\n",
    "        while True:\n",
    "            url = base_url.format(offset=offset)\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            rows = data.get(\"rows\", [])\n",
    "            total_rows = data.get(\"totalRows\", 0)\n",
    "\n",
    "            day_rows.extend(rows)\n",
    "\n",
    "            print(\n",
    "                f\"  Offset {offset}: fetched {len(rows)} rows \"\n",
    "                f\"(day total {len(day_rows)}/{total_rows})\"\n",
    "            )\n",
    "\n",
    "            if len(day_rows) >= total_rows:\n",
    "                break\n",
    "\n",
    "            offset += limit\n",
    "\n",
    "        all_data.extend(day_rows)\n",
    "        print(f\"Completed fetching for {current_day.date()}: {len(day_rows)} rows.\")\n",
    "        sum_day = sum(float(row['revenue']) for row in day_rows)\n",
    "        print(f\"Total revenue for {current_day.date()}: {sum_day}\")\n",
    "        sum_till_now = sum(float(row['revenue']) for row in all_data)\n",
    "        print(f\"Cumulative revenue till {current_day.date()}: {sum_till_now}\")\n",
    "        calculations[current_day.date()] = {\n",
    "            \"revenue\": sum_day,\n",
    "            \"revenue_so_far\": sum_till_now\n",
    "        }\n",
    "        current_day += timedelta(days=1)\n",
    "\n",
    "    return all_data, calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3332637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for 2026-02-01\n",
      "  Offset 0: fetched 970 rows (day total 970/970)\n",
      "Completed fetching for 2026-02-01: 970 rows.\n",
      "Total revenue for 2026-02-01: 18584.62719933\n",
      "Cumulative revenue till 2026-02-01: 18584.62719933\n",
      "\n",
      "Fetching data for 2026-02-02\n",
      "  Offset 0: fetched 3017 rows (day total 3017/3017)\n",
      "Completed fetching for 2026-02-02: 3017 rows.\n",
      "Total revenue for 2026-02-02: 43045.29636567\n",
      "Cumulative revenue till 2026-02-02: 61629.923565\n",
      "\n",
      "Fetching data for 2026-02-03\n",
      "  Offset 0: fetched 2529 rows (day total 2529/2529)\n",
      "Completed fetching for 2026-02-03: 2529 rows.\n",
      "Total revenue for 2026-02-03: 37337.79590231\n",
      "Cumulative revenue till 2026-02-03: 98967.71946731\n",
      "\n",
      "Fetching data for 2026-02-04\n",
      "  Offset 0: fetched 1631 rows (day total 1631/1631)\n",
      "Completed fetching for 2026-02-04: 1631 rows.\n",
      "Total revenue for 2026-02-04: 30068.99999204\n",
      "Cumulative revenue till 2026-02-04: 129036.71945935\n",
      "\n",
      "Fetching data for 2026-02-05\n",
      "  Offset 0: fetched 1390 rows (day total 1390/1390)\n",
      "Completed fetching for 2026-02-05: 1390 rows.\n",
      "Total revenue for 2026-02-05: 31380.000011739998\n",
      "Cumulative revenue till 2026-02-05: 160416.71947109\n",
      "\n",
      "Fetching data for 2026-02-06\n",
      "  Offset 0: fetched 1390 rows (day total 1390/1390)\n",
      "Completed fetching for 2026-02-06: 1390 rows.\n",
      "Total revenue for 2026-02-06: 33633.42712279\n",
      "Cumulative revenue till 2026-02-06: 194050.14659388\n",
      "\n",
      "Fetching data for 2026-02-07\n",
      "  Offset 0: fetched 904 rows (day total 904/904)\n",
      "Completed fetching for 2026-02-07: 904 rows.\n",
      "Total revenue for 2026-02-07: 19903.51000765\n",
      "Cumulative revenue till 2026-02-07: 213953.65660153\n",
      "\n",
      "Fetching data for 2026-02-08\n",
      "  Offset 0: fetched 768 rows (day total 768/768)\n",
      "Completed fetching for 2026-02-08: 768 rows.\n",
      "Total revenue for 2026-02-08: 16296.30800547\n",
      "Cumulative revenue till 2026-02-08: 230249.964607\n",
      "\n",
      "Fetching data for 2026-02-09\n",
      "  Offset 0: fetched 2051 rows (day total 2051/2051)\n",
      "Completed fetching for 2026-02-09: 2051 rows.\n",
      "Total revenue for 2026-02-09: 26351.73523619\n",
      "Cumulative revenue till 2026-02-09: 256601.69984319\n",
      "\n",
      "Fetching data for 2026-02-10\n",
      "  Offset 0: fetched 1719 rows (day total 1719/1719)\n",
      "Completed fetching for 2026-02-10: 1719 rows.\n",
      "Total revenue for 2026-02-10: 24980.82253259\n",
      "Cumulative revenue till 2026-02-10: 281582.52237578\n",
      "\n",
      "Fetching data for 2026-02-11\n",
      "  Offset 0: fetched 1493 rows (day total 1493/1493)\n",
      "Completed fetching for 2026-02-11: 1493 rows.\n",
      "Total revenue for 2026-02-11: 20490.475012220002\n",
      "Cumulative revenue till 2026-02-11: 302072.997388\n",
      "\n",
      "Fetching data for 2026-02-12\n",
      "  Offset 0: fetched 145 rows (day total 145/145)\n",
      "Completed fetching for 2026-02-12: 145 rows.\n",
      "Total revenue for 2026-02-12: 3910.00000142\n",
      "Cumulative revenue till 2026-02-12: 305982.99738942\n",
      "\n",
      "Fetching data for 2026-02-13\n",
      "  Offset 0: fetched 0 rows (day total 0/0)\n",
      "Completed fetching for 2026-02-13: 0 rows.\n",
      "Total revenue for 2026-02-13: 0\n",
      "Cumulative revenue till 2026-02-13: 305982.99738942\n"
     ]
    }
   ],
   "source": [
    "data_big, calculations = get_conversions_data_day_by_day(start_date=\"2026-02-01T00:00:00.000Z\", end_date=\"2026-02-13T00:00:00.000Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8d93897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(305982.99738942), 18007)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_big)\n",
    "df.revenue.sum(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9206b41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for insertion in 0.08286905288696289 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_conversions(df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde76cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
